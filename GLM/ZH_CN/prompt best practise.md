# 提示词工程

https://docs.bigmodel.cn/cn/guide/platform/prompt

> 掌握GLM语言模型和CogView图像生成模型的提示词技巧，获得更好的生成效果

<Info>
  本指南分享了GLM语言模型和CogView图像生成模型获得更好生成结果的策略。可以组合使用提示词技巧以获得更好的生成效果。
</Info>

## 语言模型 Prompt 工程

### 策略一：编写清晰、具体的指令

为了获得最佳的回答，用户需要向 GLM 提供清晰、具体的指令。GLM 越能明确您的需求，提供的回答质量越高。

**技巧：定义 System Prompt**

<Tip>
  System Prompt 用于设定 AI 助手行为模式的工具，包括角色设定、语言风格、任务模式和针对特定问题的具体行为指导。
</Tip>

```json
{
  "role": "system",
  "content": "你擅长从文本中提取关键信息，精确、数据驱动，重点突出关键信息，根据用户提供的文本片段提取关键数据和事实，将提取的信息以清晰的JSON格式呈现。"
}
```

**技巧：提供具体的细节要求**

在 Prompt 中添加要求模型输出内容的细节和背景信息。

<CodeGroup>
  ```text 示例
  我对太阳系的行星非常感兴趣，特别是土星。请提供关于土星的基本信息，包括其大小、组成、环系统和任何独特的天文现象。
  ```
</CodeGroup>

**技巧：让 GLM 进行角色扮演**

让 GLM 扮演角色，可以更准确地模仿该角色的行为和对话方式。

<CodeGroup>
  ```text 示例
  作为一个量子物理学家，解释量子物理学的基本原理，并简要介绍其在现代科技中的应用。
  ```
</CodeGroup>

**技巧：使用分隔符标示不同的输入部分**

<CodeGroup>
  ```text 示例
  请基于以下内容：
  """ 要总结的文章内容"""
  提炼核心观点和纲要
  ```
</CodeGroup>

**技巧：思维链提示**

<Note>
  要求模型分步骤解答问题，还要求其展示其推理过程的每个步骤。通过这种方式，可以减少不准确结果的可能性，并使用户更容易评估模型的响应。
</Note>

<CodeGroup>
  ```text 示例
  作为一个 AI 助手，你的任务是帮助用户解决复杂的数学问题。对于每个问题，你需要首先独立解决它，然后比较和评估用户的答案，并最终提供反馈。在这个过程中，请展示你的每一步推理过程。

  我有一个数学问题需要帮助:
  """问题是：一个农场有鸡和牛共35头，脚总共有94只。鸡和牛各有多少头？我的答案是鸡有23头，牛有12头"""。
  ```
</CodeGroup>

**技巧：少样本学习**

可以作为进行少样本学习的示例。这些样本可以用来引导模型模仿特定的行为和语言风格。

<CodeGroup>
  ```text 示例
  模仿这种风格
  ''' 
  1、三杯鸡在锅中欢跃，是岁月的篝火，是浪漫的乐章。
  2、炖排骨的滋味，是冬日的棉被，是乡土的回响。
  3、红烧勤鱼的鲜香，是海洋的密语，是大海的情书。
  '''
  生成新的句子。
  ```
</CodeGroup>

**指定输出长度的示例**

<Warning>
  指定按照具体的长度的输出内容，但是让模型精确的生成一个特定的字数难以实现。
</Warning>

<CodeGroup>
  ```text 示例
  请用不超过100个词的长度来总结这篇文章。
  ```
</CodeGroup>

### 策略二：提供参考资料

<Info>
  引用外部资料能有效提升模型回答的准确性。这种做法特别适用于基于文档的问答系统，因为它有助于减少错误或虚构信息的生成，同时确保回答的时效性和准确性。
</Info>

当模型受到上下文长度限制，无法引用超长文本时，可以通过 Retrieval 工具来获取文档中的语义切片来实现。

<CodeGroup>
  ```text 示例
  作为 AI 助手，你的任务是帮助用户查找和理解特定公司的规章制度。在这个场景中，你将使用搜索结果来回答用户关于公司请假政策的查询。请根据搜索结果
  """具体的搜索结果"""
  提供准确和详细的信息。
  ```
</CodeGroup>

### 策略三：将复杂任务分解为简单的子任务

<Tip>
  在处理需求复杂的任务时，错误率通常较高。为了提高效率和准确性，最佳做法是将这些复杂任务重构为一系列简单、连贯的子任务。
</Tip>

这种方法中，每个子任务的完成成果依次成为下一任务的起点，形成一个高效的工作流。这样的任务流程简化有助于提升模型整体的处理质量和可靠性，特别是在面对需要综合大量数据和深入分析的复杂问题时。

**技巧：意图理解和实体提取**

要求大模型输出的内容要直接给到后端服务接口使用，所以大模型一定要按照固定格式输出格式，以便于接口解析模型输出内容，防止报错。

<CodeGroup>
  ```text 示例
  当你理解用户的预约会议室的意图时，提取相关的实体，并且以 Json 格式输出。
  ```
</CodeGroup>

**技巧：总结上文关键信息**

在长对话中，为了确保对话的连贯性和有效性，对之前的交流内容进行精炼和总结，可以保持对话的焦点、减少重复和混乱、加快模型处理速度。

**技巧：分段归纳长文档并逐步构建完整摘要**

<Note>
  由于模型处理文本的上下文长度有限，它无法一次性总结超出特定长度的文本。例如，在总结一本长书时，我们可以采用分步骤的方法，逐章节进行总结。
</Note>

各章节的摘要可以组合在一起，再进行进一步的概括，形成更为精炼的总摘要。这个过程可以重复进行，直到整本书的内容被完整总结。如果后续章节的理解需要依赖于前面的内容，可以在总结时包含必要的上下文信息。