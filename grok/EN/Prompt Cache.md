### [Cached prompt tokens](https://docs.x.ai/docs/key-information/consumption-and-rate-limits#cached-prompt-tokens)

When you send the same prompt multiple times, we may cache your prompt tokens. This would result in reduced cost for these tokens at the cached token rate, and a quicker response.