# 提示设计策略

https://ai.google.dev/gemini-api/docs/prompting-strategies

*提示设计*是创建提示或自然语言请求的过程，旨在从语言模型中引出准确、高质量的响应。

本页面介绍了基本概念、策略和最佳实践，以帮助您开始设计提示，从而充分利用 Gemini AI 模型。

## 特定主题的提示指南

正在寻找更具体的提示策略？请查看我们的其他提示指南：

- [使用媒体文件进行提示](https://ai.google.dev/gemini-api/docs/files#prompt-guide)
- 使用 [Imagen](https://ai.google.dev/gemini-api/docs/imagen#imagen-prompt-guide) 和 [Gemini 原生图像生成](https://ai.google.dev/gemini-api/docs/image-generation#prompt-guide)进行图像生成提示
- [视频生成提示](https://ai.google.dev/gemini-api/docs/video#prompt-guide)

您可以在[提示库](https://ai.google.dev/gemini-api/prompts)中找到其他示例提示，旨在以交互方式展示本指南中共享的许多概念。

## 清晰具体的指令

自定义模型行为的一种有效且高效的方法是为其提供清晰具体的指令。指令可以是问题的形式、分步任务，或者像规划用户体验和心态一样复杂。

### 输入

输入是提示中您希望模型为其提供响应的必需文本。输入可以是模型回答的问题（问题输入）、模型执行的任务（任务输入）、模型操作的实体（实体输入），或模型完成或继续的部分输入（补全输入）。

| **输入类型** | **提示** | **生成的输出** |
| :------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| 问题 | `一个专门销售干花花束的花店叫什么名字好？创建一个只有名字的 5 个选项列表。` | `这里有 10 个专门销售干花的花店名称：1. 永恒花开 2. 干花与喜悦 3. 花瓣蜜饯 4. 野花私语 5. 永恒绽放` |
| 任务 | `给我一份我露营旅行必须携带的物品的简单列表。列表应该有 5 项。` | `1. **帐篷：** 您的避风港。 2. **睡袋：** 保持温暖舒适。 3. **睡垫：** 隔热和缓冲，让您睡个好觉。 4. **头灯或手电筒：** 夜间活动照明。 5. **急救箱：** 为轻伤做好准备。` |
| 实体 | `将以下项目分类为 [大，小]：大象 老鼠 蜗牛` | `这是分类： * **大象：** 大 * **老鼠：** 小 * **蜗牛：** 小` |

#### 部分输入补全

生成式语言模型的工作方式类似于高级自动补全工具。当您提供部分内容时，模型可以提供其余内容或它认为是该内容延续的响应。这样做时，如果您包含任何示例或上下文，模型可以将这些示例或上下文考虑在内。

以下示例提供了一个带有指令和实体输入的提示：

**Prompt：**

```
对于给定的订单，返回一个 JSON 对象，该对象具有 cheeseburger、hamburger、fries 或 drink 字段，值为数量。

订单：一个汉堡和一杯饮料。
```

**响应：**

```
{
"cheeseburger": 0,
"hamburger": 1,
"fries": 0,
"drink": 1
}
```

虽然模型按照提示执行了操作，但用自然语言写出指令有时可能具有挑战性，并且给模型的解释留下了很大的空间。例如，餐厅的菜单可能包含许多项目。为了减小 JSON 响应的大小，您可能希望省略未订购的项目。在这种情况下，您可以给出一个示例和一个[响应前缀](https://ai.google.dev/gemini-api/docs/prompting-strategies#prefixes)并让模型完成它：

**Prompt：**

````
有效字段为 cheeseburger、hamburger、fries 和 drink。
订单：给我一个芝士汉堡和薯条
输出：
```
{
"cheeseburger": 1,
"fries": 1
}
```
订单：我想要两个汉堡、一杯饮料和薯条。
输出：
````

**响应：**

```
{
"hamburger": 2,
"drink": 1,
"fries": 1
}
```

请注意，“cheeseburger”是如何从输出中排除的，因为它不是订单的一部分。

### 约束

指定阅读提示或生成响应的任何约束。您可以告诉模型该做什么和不该做什么。例如，您可以在提示中指定一个约束，说明您希望摘要有多长：

**Prompt：**

```
用一句话总结这段文字：
文本：量子计算机利用量子力学现象来执行比任何现代传统计算机快指数级的计算。在非常微小的尺度上，物理物质既表现为粒子又表现为波，量子计算使用专门的硬件来利用这种行为。量子设备的工作原理超出了经典物理学的范围。当大规模部署时，量子计算机可用于各种应用，例如：在网络安全中破解现有的加密方法，同时帮助研究人员创建新的加密方法，在气象学中开发更好的天气预报等。然而，目前最先进的量子计算机在很大程度上仍处于实验阶段且不切实际。
```

**响应：**

```
利用量子力学现象，量子计算机可以比传统计算机快指数级地执行计算，用于网络安全和气象学等潜在应用，尽管它们目前在很大程度上仍处于实验阶段且不切实际。
```

### 响应格式

您可以给出指定响应格式的指令。例如，您可以要求将响应格式化为表格、项目符号列表、电梯演讲、关键字、句子或段落。以下系统指令告诉模型在其响应中更加健谈：

**系统指令**

```
所有问题都应全面回答并提供详细信息，除非用户明确要求简洁的响应。
```

**Prompt**

```
在 2025 年，开设一家销售 DVD 的企业有什么好主意？
```

**响应：**

```
在 2025 年开设一家销售 DVD 的企业面临着巨大挑战，因为数字流媒体和点播服务占据了压倒性的主导地位；因此，“明智”的方法需要一个高度专业化的利基市场，一个超越光盘本身的强大价值主张，并且可能专注于社区或收藏家市场而不是主流消费。

以下是 2025 年一家明智的 DVD 企业可能需要具备的要素：

1. 极端利基专业化：您无法与流媒体库竞争。您的业务必须专注于数字媒体不容易或根本不提供的内容。这可能包括：

* 绝版和稀有影片：寻找从未以数字形式发行或目前在主要流媒体平台上不可用的电影或电视节目。
....
```

#### 使用补全策略格式化响应

[补全策略](https://ai.google.dev/gemini-api/docs/prompting-strategies#completion)也可以帮助格式化响应。以下示例提示模型创建一篇论文大纲：

**提示：**

```
为一篇关于蜂鸟的论文创建一个大纲。
```

**Prompt：**

```
这是一篇关于蜂鸟的论文可能的大纲：

I. 引言
A. 开头：以一个关于蜂鸟的迷人事实或描述开始（例如，它们的速度、彩虹色的羽毛或微小的体型）。
B. 背景：简要介绍蜂鸟——它们在哪里被发现（美洲），它们作为独特鸟类的声誉。
C. 论文陈述：陈述论文的要点，可以是关于蜂鸟卓越的适应性、行为和生态重要性。

II. 外观和识别
.....
```

提示没有指定大纲的格式，模型为您选择了一种格式。要让模型以特定格式返回大纲，您可以添加代表大纲开头的文本，并让模型根据您启动的模式完成它。

**Prompt：**

```
为一篇关于蜂鸟的论文创建一个大纲。
I. 引言
*
```

**响应：**

```
好的，这是一篇关于蜂鸟的论文的大纲，从您提供的引言开始：

I. 引言
* 开头：以一个关于蜂鸟的迷人事实或描述开始（例如，它们的速度、彩虹色的羽毛或微小的体型）。
* 背景：简要介绍蜂鸟——它们在哪里被发现（美洲），它们作为独特鸟类的声誉，以及它们的一般特征。
* 论文陈述：陈述论文的要点，重点关注使蜂鸟非凡的卓越适应性、行为和生态意义。
.....
```

## 零样本 vs 少样本提示

您可以在提示中包含示例，向模型展示正确的做法。模型会尝试从示例中识别模式和关系，并在生成响应时应用它们。包含一些示例的提示称为*少样本*提示，而没有提供示例的提示称为*零样本*提示。少样本提示通常用于规范模型响应的格式、措辞、范围或一般模式。使用具体且多样的示例来帮助模型缩小其关注范围并生成更准确的结果。

我们建议始终在您的提示中包含少样本示例。没有少样本示例的提示可能效果较差。事实上，如果您的示例足够清晰地展示了手头的任务，您可以从提示中删除指令。

以下零样本提示要求模型选择最佳解释。

**Prompt：**

```
请选择问题的最佳解释：

问题：雪是如何形成的？
解释 1：当空气中的水蒸气在大气中冻结成冰晶时形成雪，当它们穿过大气层并积聚在地面上时，它们可以结合并长成雪花。
解释 2：水蒸气冻结成冰晶形成雪。
答案：
```

**响应：**

```
解释 1 是更好的解释，因为它提供了有关该过程的更多细节，包括冰晶如何在穿过大气层时结合并长成雪花。
```

如果您的用例要求模型生成简洁的响应，您可以在提示中包含偏爱简洁响应的示例。

以下提示提供了两个偏爱较短解释的示例。在响应中，您可以看到示例引导模型选择了较短的解释 (`解释 2`)，而不是像之前那样选择较长的解释 (`解释 1`)。

**Prompt：**

```
以下是一些显示问题、解释和答案格式的示例：

问题：为什么天空是蓝色的？
解释 1：天空之所以呈现蓝色，是因为瑞利散射，它导致较短的蓝色波长的光比更长的红色波长更容易散射，从而使天空看起来是蓝色的。
解释 2：由于瑞利散射效应。
答案：解释 2

问题：地震的原因是什么？
解释 1：地壳中能量的突然释放。
解释 2：当地壳板块突然滑动或断裂时会发生地震，导致能量释放，产生可以震动地面并造成破坏的地震波。
答案：解释 1

现在，根据上面给出的示例格式回答以下问题：

问题：雪是如何形成的？
解释 1：当空气中的水蒸气在大气中冻结成冰晶时形成雪，当它们穿过大气层并积聚在地面上时，它们可以结合并长成雪花。
解释 2：水蒸气冻结成冰晶形成雪。
答案：
```

**响应：**

```
答案：解释 2
```

### 最佳示例数量

像 Gemini 这样的模型通常可以通过几个示例来掌握模式，但您可能需要试验在提示中提供多少示例以获得最佳结果。同时，如果您包含太多示例，模型可能会开始[过拟合](https://developers.google.com/machine-learning/glossary#overfitting)响应到示例。

### 模式 vs 反模式

使用示例向模型展示要遵循的模式比使用示例向模型展示要避免的反模式更有效。

⛔ **负面模式：**

**示例**

```
不要用问题结束俳句：
俳句很有趣
一首简短的诗
你不喜欢吗？
```

✅ **正面模式：**

**示例**

```
总是用断言结束俳句：
俳句很有趣
一首简短的诗
写起来很愉快
```

### 一致的格式

确保少样本示例的结构和格式相同，以避免响应格式不理想。在提示中添加少样本示例的主要目标之一是向模型展示响应格式。因此，确保所有示例的格式一致至关重要，尤其要注意 XML 标签、空格、换行符和示例分隔符。

## 添加上下文

您可以在提示中包含模型解决问题所需的指令和信息，而不是假设模型拥有所有必需的信息。这种上下文信息有助于模型理解您要求它做什么的约束和细节。

以下示例要求模型为路由器提供故障排除指南：

**Prompt：**

```
我应该怎么做才能修复断开的 wifi？我的 Google Wifi 路由器上的灯是黄色的，并且缓慢闪烁。
```

**响应：**

```
Google Wifi 路由器上的黄色闪烁灯通常表示互联网连接有问题。以下是排除故障和解决问题的一些步骤：
1. 重新启动您的路由器和调制解调器：
- 从电源插座拔下您的调制解调器并等待 30 秒。
- 将您的调制解调器插回电源并等待其完全启动。
- 拔下您的 Google Wifi 路由器并等待 30 秒。
- 将您的 Google Wifi 路由器插回电源并等待其完全启动。
.....
```

响应看起来像是通用的故障排除信息，不特定于路由器或 LED 指示灯的状态。

要为特定路由器自定义响应，您可以在提示中添加路由器的故障排除指南作为上下文，以便它在提供响应时参考。

**Prompt：**

```
使用下面的文本回答问题。仅使用提供的文本进行响应。
问题：我应该怎么做才能修复断开的 wifi？我的 Google Wifi 路由器上的灯是黄色的，并且缓慢闪烁。

文本：
颜色：缓慢闪烁的黄色
含义：存在网络错误。
该怎么做：
检查以太网电缆是否已连接到您的路由器和调制解调器，并且两个设备都已打开。您可能需要拔下并重新插入每个设备。

颜色：快速闪烁的黄色
含义：您正在按住重置按钮并正在恢复此设备的出厂设置。
该怎么做：
如果您继续按住重置按钮，大约 12 秒后，指示灯将变为纯黄色。一旦它变成纯黄色，就松开恢复出厂设置按钮。

颜色：纯黄色
含义：路由器正在恢复出厂设置。
该怎么做：
这最多可能需要 10 分钟。完成后，设备将自行重置并开始闪烁白色，让您知道它已准备好进行设置。

颜色：纯红色
含义：出错了。
该怎么做：
严重故障。将路由器恢复出厂设置。如果指示灯保持红色，请联系 Wifi 客户支持。
```

**响应：**

```
检查以太网电缆是否已连接到您的路由器和调制解调器，并且两个设备都已打开。您可能需要拔下并重新插入每个设备。
```

## 添加前缀

前缀是您添加到提示内容中的单词或短语，可以有多种用途，具体取决于您放置前缀的位置：

- **输入前缀：** 在输入中添加前缀可以向模型指示输入的语义上有意义的部分。例如，前缀“English:”和“French:” demarcate 两种不同的语言。
- **输出前缀：** 即使输出是由模型生成的，您也可以在提示中为输出添加前缀。输出前缀为模型提供了有关预期响应的信息。例如，输出前缀“JSON:”向模型指示输出应为 JSON 格式。
- **示例前缀：** 在少样本提示中，向示例添加前缀提供了模型在生成输出时可以使用的标签，这使得解析输出内容更容易。

在以下示例中，“Text:”是输入前缀，“The answer is:”是输出前缀。

**Prompt：**

```
将文本分类为以下类别之一。
- 大
- 小
文本：犀牛
答案是：大
文本：老鼠
答案是：小
文本：蜗牛
答案是：小
文本：大象
答案是：
```

**响应：**

```
答案是：大
```

## 将提示分解为组件

对于需要复杂提示的用例，您可以通过将事物分解为更简单的组件来帮助模型管理这种复杂性。

1. **分解指令：** 与其在一个提示中包含许多指令，不如为每个指令创建一个提示。您可以根据用户的输入选择要处理的提示。
2. **链接提示：** 对于涉及多个顺序步骤的复杂任务，将每个步骤都设为一个提示，并按顺序将提示链接在一起。在这个顺序的提示链中，序列中一个提示的输出成为下一个提示的输入。序列中最后一个提示的输出是最终输出。
3. **聚合响应：** 聚合是指您希望对数据的不同部分执行不同的并行任务，并聚合结果以产生最终输出。例如，您可以告诉模型对数据的第一部分执行一个操作，对数据的其余部分执行另一个操作，然后聚合结果。

## 试验模型参数

您发送给模型的每个调用都包含控制模型如何生成响应的参数值。对于不同的参数值，模型可以生成不同的结果。试验不同的参数值以获得任务的最佳值。不同模型可用的参数可能不同。最常见的参数如下：

1. **最大输出令牌数：** 指定响应中可以生成的最大令牌数。一个令牌大约是四个字符。100 个令牌大约相当于 60-80 个单词。
2. **温度：** 温度控制令牌选择中的随机性程度。温度用于在响应生成期间进行采样，这在应用 `topP` 和 `topK` 时发生。较低的温度适用于需要更具确定性或较少开放式响应的提示，而较高的温度可以导致更多样化或创造性的结果。温度为 0 是确定性的，这意味着始终选择最高概率的响应。
3. **`topK`：** `topK` 参数更改模型如何选择输出令牌。`topK` 为 1 意味着所选令牌是模型词汇表中所有令牌中最可能的（也称为贪婪解码），而 `topK` 为 3 意味着下一个令牌是使用温度从 3 个最可能的令牌中选择的。对于每个令牌选择步骤，都会对概率最高的 `topK` 个令牌进行采样。然后根据 `topP` 进一步过滤令牌，并使用温度采样选择最终令牌。
4. **`topP`：** `topP` 参数更改模型如何选择输出令牌。令牌从最可能到最不可能选择，直到它们的概率总和等于 `topP` 值。例如，如果令牌 A、B 和 C 的概率分别为 0.3、0.2 和 0.1，并且 `topP` 值为 0.5，那么模型将通过使用温度选择 A 或 B 作为下一个令牌，并排除 C 作为候选。默认的 `topP` 值为 0.95。
5. **`stop_sequences`：** 设置停止序列以告诉模型停止生成内容。停止序列可以是任何字符序列。尽量避免使用可能出现在生成内容中的字符序列。

## 提示迭代策略

提示设计有时可能需要几次迭代才能始终获得您想要的响应。本节提供了一些关于在迭代提示时可以尝试的事情的指导：

1. **使用不同的措辞：** 在提示中使用不同的单词或措辞通常会从模型中产生不同的响应，即使它们都意味着相同的事情。如果您没有从提示中获得预期的结果，请尝试重新措辞。

   ```
   版本 1：
   我如何烤一个派？

   版本 2：
   建议一个派的食谱。

   版本 3：
   有什么好的派食谱？
   ```

2. **切换到类似的任务：** 如果您无法让模型为一个任务遵循您的指令，请尝试为其提供一个能够达到相同结果的类似任务的指令。

   此提示告诉模型使用预定义的类别对一本书进行分类：

   **Prompt：**

   ```
   《奥德赛》属于哪个类别：
   惊悚
   科幻
   神话
   传记
   ```

   **响应：**

   ```
   《奥德赛》属于**神话**类别。
   
   原因如下：
   
   * **神话：** 《奥德赛》讲述了希腊神话英雄奥德修斯在特洛伊战争后回家的旅程。它以希腊神话中常见的众神、怪物和超自然事件为特色。
   .....
   ```

   响应是正确的，但模型没有停留在选项的范围内。您还希望模型只用其中一个选项来响应，而不是用一个完整的句子。在这种情况下，您可以将指令重新表述为一个多项选择题，并要求模型选择一个选项。

   **Prompt：**

   ```
   多项选择题：以下哪个选项描述了《奥德赛》这本书？
   选项：
   
   惊悚
   科幻
   神话
   传记
   ```
   
   **响应：**
   
   ```
   正确答案是神话。
   ```
   
3. **更改提示内容的顺序：** 提示中内容的顺序有时会影响响应。尝试更改内容顺序，看看它如何影响响应。

   ```
   	版本 1：
      [示例]
      [上下文]
      [输入]
   
      版本 2：
      [输入]
      [示例]
      [上下文]
   
      版本 3：
      [示例]
      [输入]
      [上下文]
## 回退响应

回退响应是当提示或响应触发安全过滤器时模型返回的响应。回退响应的一个示例是“我无法提供帮助，因为我只是一个语言模型。”

如果模型以回退响应进行响应，请尝试增加温度。

## 应避免的事项

- 避免依赖模型生成事实信息。
- 谨慎用于数学和逻辑问题。

## 生成模型内幕

本节旨在回答这个问题 - ***生成模型的响应中是否存在随机性，还是它们是确定性的？***

简短的回答 - 两者都是。当您提示生成模型时，文本响应分两个阶段生成。在第一阶段，生成模型处理输入提示并生成一个可能接下来出现的标记（单词）的**概率分布**。例如，如果您提示输入文本“The dog jumped over the ...”，生成模型将生成一个可能的下一个单词的数组：

```json
[("fence", 0.77), ("ledge", 0.12), ("blanket", 0.03), ...]
```

这个过程是确定性的；生成模型每次输入相同的提示文本时都会产生相同的分布。

在第二阶段，生成模型通过几种解码策略之一将这些分布转换为实际的文本响应。一个简单的解码策略可能在每个时间步选择最可能的标记。这个过程总是确定性的。但是，您也可以选择通过对模型返回的分布进行*随机采样*来生成响应。这个过程将是随机的。通过设置温度来控制此解码过程中允许的随机性程度。温度为 0 意味着只选择最可能的标记，并且没有随机性。相反，高温会在模型选择的标记中注入高度的随机性，从而导致更出乎意料、更令人惊讶的模型响应。
